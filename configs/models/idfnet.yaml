target: idf.models.lit_a_denoising.LitADenoising
params:
  misc_config:
    compile: false             # Set true to compile the model (PyTorch 2.x) for potential speedup.
    warmup: 5000               # Number of warmup iterations.

    # IDF inference options
    adaptive_iteration: False  # If true, enable early halting based on kernel change metric (see halt_threshold in model).
    max_iteration: ~           # Upper bound denoising iteration during inference (default = 10).

  data_config:
    train:
      input_key: LQ            # Key in the training batch dict for noisy / low-quality input.
      target_key: GT           # Key for clean ground-truth target.
    validate:                  # Validation sets (match dataset entries in "val_config" of configs/train/test_lit_denoising.yaml).
      CBSD68_G:
        input_key: LQ
        target_key: GT
      Kodak24_G:
        input_key: LQ
        target_key: GT
      McMaster_G:
        input_key: LQ
        target_key: GT
      Urban100_G:
        input_key: LQ
        target_key: GT

    norm:                      # Data normalization.
      mu_data: 0.0
      sigma_data: 0.5

      # Raw dataset channel-wise statistics.
      raw_mean : [0.36187348, 0.4361255,  0.4335091]  # Per-channel raw mean (RGB order) from CBSD432 subset.
      raw_std  : [0.19088039, 0.19967876, 0.21309015] # Per-channel raw standard deviation.

  optimizer_config:
    target: torch.optim.AdamW
    params:
      lr: !!float 1e-4         # Base learning rate.
      weight_decay: !!float 1e-4
      betas: [0.9, 0.999]
  
  loss_config:
    target: idf.losses.basic_loss.L1Loss  # Reconstruction loss.
    params:
      loss_weight: !!float 1.0
      reduction: mean

  denoiser_config:
    target: idf.archs.idf_arch.IDFNet  # iterative dynamic filtering network.
    params:
      num_iter: 10             # Maximum iterative denoising steps.
      kernel_size: 3           # Spatial size (k) of adaptive kernels (k x k).
      num_channels: 3          # Image channels.
      hidden_channels: 64      # Internal feature width in DID block.
      power_alpha: 3.0         # Exponent for power normalization of predicted kernels (controls sharpness).
      halt_threshold: 0.015    # Early-stop tolerance on kernel center change (lower => more iterations before halting).
